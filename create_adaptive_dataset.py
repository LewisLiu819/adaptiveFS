"""
ä¸ºAdaptiveFSåˆ›å»ºç¬¦åˆæ ¼å¼è¦æ±‚çš„åŒ»å­¦é—®å·æ•°æ®é›†

æ ¹æ®AdaptiveFSçš„è¦æ±‚åˆ›å»ºï¼š
1. small_data50.npy - å½¢çŠ¶ä¸º(n,50)çš„å®å€¼numpyæ•°ç»„
2. names_small50.npy - åŒ…å«50ä¸ªé—®é¢˜åç§°çš„numpyæ•°ç»„  
3. labels.npy - å¯¹åº”çš„æ ‡ç­¾æ•°ç»„

æ•°æ®é›†æ¨¡æ‹ŸçœŸå®çš„åŒ»å­¦é—®å·è°ƒæŸ¥ï¼ŒåŒ…å«50ä¸ªåŒ»å­¦ç›¸å…³é—®é¢˜
"""

import numpy as np
import os
from sklearn.preprocessing import MinMaxScaler

def create_medical_question_names():
    """åˆ›å»º50ä¸ªåŒ»å­¦é—®å·é—®é¢˜åç§°"""
    
    question_names = [
        # åŸºæœ¬äººå£ç»Ÿè®¡å­¦ä¿¡æ¯ (0-9)
        'age_p',           # å¹´é¾„
        'sex',             # æ€§åˆ« (1=ç”·, 2=å¥³)
        'hiscodi32',       # ç§æ—ç¼–ç  (0=éè¥¿ç­ç‰™è£”, 1=è¥¿ç­ç‰™è£”)
        'bmi',             # ä½“è´¨é‡æŒ‡æ•°
        'education_level', # æ•™è‚²æ°´å¹³
        'income_level',    # æ”¶å…¥æ°´å¹³
        'marital_status',  # å©šå§»çŠ¶å†µ
        'employment_status', # å°±ä¸šçŠ¶å†µ
        'insurance_status',  # ä¿é™©çŠ¶å†µ
        'region_code',     # åœ°åŒºä»£ç 
        
        # ç”Ÿæ´»æ–¹å¼å› ç´  (10-19)
        'smoking_status',      # å¸çƒŸçŠ¶å†µ
        'alcohol_consumption', # é¥®é…’æƒ…å†µ
        'exercise_frequency',  # è¿åŠ¨é¢‘ç‡
        'diet_quality',        # é¥®é£Ÿè´¨é‡
        'sleep_hours',         # ç¡çœ æ—¶é—´
        'stress_level',        # å‹åŠ›æ°´å¹³
        'caffeine_intake',     # å’–å•¡å› æ‘„å…¥
        'physical_activity',   # ä½“åŠ›æ´»åŠ¨
        'sedentary_time',      # ä¹…åæ—¶é—´
        'social_support',      # ç¤¾ä¼šæ”¯æŒ
        
        # ç—‡çŠ¶å’Œä¸»è¯‰ (20-29)
        'chest_pain',          # èƒ¸ç—›
        'shortness_of_breath', # å‘¼å¸å›°éš¾
        'fatigue',             # ç–²åŠ³
        'dizziness',           # å¤´æ™•
        'headache',            # å¤´ç—›
        'nausea',              # æ¶å¿ƒ
        'abdominal_pain',      # è…¹ç—›
        'joint_pain',          # å…³èŠ‚ç—›
        'back_pain',           # èƒŒç—›
        'sleep_problems',      # ç¡çœ é—®é¢˜
        
        # æ—¢å¾€ç—…å² (30-39)
        'diabetes_history',       # ç³–å°¿ç—…å²
        'hypertension_history',   # é«˜è¡€å‹å²
        'heart_disease_history',  # å¿ƒè„ç—…å²
        'stroke_history',         # ä¸­é£å²
        'cancer_history',         # ç™Œç—‡å²
        'kidney_disease_history', # è‚¾ç—…å²
        'liver_disease_history',  # è‚ç—…å²
        'lung_disease_history',   # è‚ºç—…å²
        'mental_health_history',  # ç²¾ç¥å¥åº·å²
        'family_heart_disease',   # å®¶æ—å¿ƒè„ç—…å²
        
        # å®éªŒå®¤æ£€æŸ¥å’Œç”Ÿç†æŒ‡æ ‡ (40-49)
        'blood_pressure_systolic',  # æ”¶ç¼©å‹
        'blood_pressure_diastolic', # èˆ’å¼ å‹
        'heart_rate',               # å¿ƒç‡
        'blood_glucose',            # è¡€ç³–
        'cholesterol_total',        # æ€»èƒ†å›ºé†‡
        'cholesterol_hdl',          # é«˜å¯†åº¦è„‚è›‹ç™½èƒ†å›ºé†‡
        'cholesterol_ldl',          # ä½å¯†åº¦è„‚è›‹ç™½èƒ†å›ºé†‡
        'triglycerides',            # ç”˜æ²¹ä¸‰é…¯
        'hemoglobin',               # è¡€çº¢è›‹ç™½
        'white_blood_cell_count'    # ç™½ç»†èƒè®¡æ•°
    ]
    
    assert len(question_names) == 50, f"åº”è¯¥æœ‰50ä¸ªé—®é¢˜ï¼Œå®é™…æœ‰{len(question_names)}ä¸ª"
    
    return np.array(question_names, dtype='<U32')  # ä½¿ç”¨Unicodeå­—ç¬¦ä¸²

def generate_realistic_medical_data(n_patients=1000, random_seed=42):
    """ç”ŸæˆçœŸå®çš„åŒ»å­¦é—®å·æ•°æ®"""
    
    np.random.seed(random_seed)
    
    # åˆå§‹åŒ–æ•°æ®çŸ©é˜µ
    data = np.zeros((n_patients, 50))
    
    # ç”ŸæˆåŸºæœ¬äººå£ç»Ÿè®¡å­¦ä¿¡æ¯ (0-9)
    data[:, 0] = np.random.normal(45, 15, n_patients)  # age_p: å¹´é¾„ï¼Œå‡å€¼45ï¼Œæ ‡å‡†å·®15
    data[:, 0] = np.clip(data[:, 0], 18, 85)  # é™åˆ¶åœ¨18-85å²
    
    data[:, 1] = np.random.choice([1, 2], n_patients, p=[0.48, 0.52])  # sex: æ€§åˆ«
    data[:, 2] = np.random.choice([0, 1], n_patients, p=[0.83, 0.17])  # hiscodi32: ç§æ—
    
    # BMI: æ­£æ€åˆ†å¸ƒï¼Œå‡å€¼25ï¼Œæ ‡å‡†å·®5
    data[:, 3] = np.random.normal(25, 5, n_patients)
    data[:, 3] = np.clip(data[:, 3], 15, 50)
    
    # å…¶ä»–äººå£ç»Ÿè®¡å­¦ç‰¹å¾ (4-9)
    for i in range(4, 10):
        data[:, i] = np.random.normal(0, 1, n_patients)
    
    # ç”Ÿæ´»æ–¹å¼å› ç´  (10-19)
    # å¸çƒŸçŠ¶å†µï¼š0=ä»ä¸ï¼Œ1=ä»¥å‰ï¼Œ2=ç°åœ¨
    data[:, 10] = np.random.choice([0, 1, 2], n_patients, p=[0.6, 0.25, 0.15])
    
    # é¥®é…’ï¼š0=ä»ä¸ï¼Œ1=å¶å°”ï¼Œ2=ç»å¸¸
    data[:, 11] = np.random.choice([0, 1, 2], n_patients, p=[0.3, 0.5, 0.2])
    
    # è¿åŠ¨é¢‘ç‡ï¼šå¤©/å‘¨
    data[:, 12] = np.random.poisson(2.5, n_patients)
    data[:, 12] = np.clip(data[:, 12], 0, 7)
    
    # å…¶ä»–ç”Ÿæ´»æ–¹å¼å› ç´  (13-19)
    for i in range(13, 20):
        data[:, i] = np.random.normal(0, 1, n_patients)
    
    # ç—‡çŠ¶å’Œä¸»è¯‰ (20-29) - å¤§å¤šæ•°ä¸º0-3çš„ä¸¥é‡ç¨‹åº¦è¯„åˆ†
    for i in range(20, 30):
        # ä½¿ç”¨æ³Šæ¾åˆ†å¸ƒç”Ÿæˆç—‡çŠ¶ä¸¥é‡ç¨‹åº¦
        data[:, i] = np.random.poisson(0.5, n_patients)
        data[:, i] = np.clip(data[:, i], 0, 3)
    
    # æ—¢å¾€ç—…å² (30-39) - äºŒå…ƒå˜é‡ 0=æ— ï¼Œ1=æœ‰
    disease_prevalence = [0.08, 0.25, 0.06, 0.03, 0.04, 0.03, 0.02, 0.05, 0.15, 0.12]
    for i, prevalence in enumerate(disease_prevalence):
        data[:, 30+i] = np.random.choice([0, 1], n_patients, p=[1-prevalence, prevalence])
    
    # å®éªŒå®¤æ£€æŸ¥å’Œç”Ÿç†æŒ‡æ ‡ (40-49)
    # æ”¶ç¼©å‹
    data[:, 40] = np.random.normal(120, 15, n_patients)
    data[:, 40] = np.clip(data[:, 40], 90, 180)
    
    # èˆ’å¼ å‹
    data[:, 41] = np.random.normal(80, 10, n_patients)
    data[:, 41] = np.clip(data[:, 41], 60, 120)
    
    # å¿ƒç‡
    data[:, 42] = np.random.normal(70, 10, n_patients)
    data[:, 42] = np.clip(data[:, 42], 50, 100)
    
    # è¡€ç³–
    data[:, 43] = np.random.normal(95, 15, n_patients)
    data[:, 43] = np.clip(data[:, 43], 70, 200)
    
    # æ€»èƒ†å›ºé†‡
    data[:, 44] = np.random.normal(190, 30, n_patients)
    data[:, 44] = np.clip(data[:, 44], 120, 300)
    
    # HDLèƒ†å›ºé†‡
    data[:, 45] = np.random.normal(50, 12, n_patients)
    data[:, 45] = np.clip(data[:, 45], 30, 80)
    
    # LDLèƒ†å›ºé†‡
    data[:, 46] = np.random.normal(110, 25, n_patients)
    data[:, 46] = np.clip(data[:, 46], 70, 180)
    
    # ç”˜æ²¹ä¸‰é…¯
    data[:, 47] = np.random.normal(120, 40, n_patients)
    data[:, 47] = np.clip(data[:, 47], 50, 300)
    
    # è¡€çº¢è›‹ç™½
    data[:, 48] = np.random.normal(14, 2, n_patients)
    data[:, 48] = np.clip(data[:, 48], 10, 18)
    
    # ç™½ç»†èƒè®¡æ•°
    data[:, 49] = np.random.normal(6.5, 1.5, n_patients)
    data[:, 49] = np.clip(data[:, 49], 3, 12)
    
    return data

def generate_cardiovascular_risk_labels(data):
    """åŸºäºæ‚£è€…ç‰¹å¾ç”Ÿæˆå¿ƒè¡€ç®¡ç–¾ç—…é£é™©æ ‡ç­¾"""
    
    n_patients = data.shape[0]
    risk_scores = np.zeros(n_patients)
    
    # å¹´é¾„å› å­
    age_factor = (data[:, 0] - 30) / 50  # æ ‡å‡†åŒ–å¹´é¾„
    risk_scores += 0.25 * np.clip(age_factor, 0, 1)
    
    # æ€§åˆ«å› å­ (ç”·æ€§é£é™©æ›´é«˜)
    gender_factor = (data[:, 1] == 1).astype(float)
    risk_scores += 0.1 * gender_factor
    
    # BMIå› å­
    bmi = data[:, 3]
    bmi_factor = np.where(bmi > 30, 0.15, 
                 np.where(bmi > 25, 0.05, 0))
    risk_scores += bmi_factor
    
    # å¸çƒŸå› å­
    smoking_factor = data[:, 10] * 0.1  # 0, 0.1, 0.2
    risk_scores += smoking_factor
    
    # é«˜è¡€å‹å²
    hypertension_factor = data[:, 31] * 0.2
    risk_scores += hypertension_factor
    
    # ç³–å°¿ç—…å²
    diabetes_factor = data[:, 30] * 0.15
    risk_scores += diabetes_factor
    
    # å¿ƒè„ç—…å®¶æ—å²
    family_history_factor = data[:, 39] * 0.1
    risk_scores += family_history_factor
    
    # è¡€å‹å› å­
    systolic_bp = data[:, 40]
    bp_factor = np.where(systolic_bp > 140, 0.15,
                np.where(systolic_bp > 130, 0.1, 0))
    risk_scores += bp_factor
    
    # èƒ†å›ºé†‡å› å­
    total_cholesterol = data[:, 44]
    chol_factor = np.where(total_cholesterol > 240, 0.1,
                  np.where(total_cholesterol > 200, 0.05, 0))
    risk_scores += chol_factor
    
    # ç—‡çŠ¶å› å­
    chest_pain_factor = data[:, 20] * 0.05
    shortness_breath_factor = data[:, 21] * 0.05
    risk_scores += chest_pain_factor + shortness_breath_factor
    
    # æ·»åŠ éšæœºå™ªå£°
    risk_scores += np.random.normal(0, 0.1, n_patients)
    
    # è½¬æ¢ä¸ºäºŒå…ƒæ ‡ç­¾ (0: ä½é£é™©, 1: é«˜é£é™©)
    threshold = np.percentile(risk_scores, 70)  # 30%çš„æ‚£è€…ä¸ºé«˜é£é™©
    labels = (risk_scores > threshold).astype(int)
    
    return labels

def create_adaptivefs_dataset(n_patients=1000, save_dir='./Data'):
    """åˆ›å»ºå®Œæ•´çš„AdaptiveFSæ•°æ®é›†"""
    
    print(f"åˆ›å»ºAdaptiveFSæ•°æ®é›†ï¼Œæ‚£è€…æ•°é‡: {n_patients}")
    
    # 1. åˆ›å»ºé—®é¢˜åç§°
    question_names = create_medical_question_names()
    print(f"âœ“ åˆ›å»ºäº† {len(question_names)} ä¸ªé—®é¢˜åç§°")
    
    # 2. ç”Ÿæˆæ‚£è€…æ•°æ®
    data = generate_realistic_medical_data(n_patients)
    print(f"âœ“ ç”Ÿæˆäº† {data.shape[0]} ä¸ªæ‚£è€…çš„æ•°æ®ï¼Œæ¯ä¸ªæ‚£è€… {data.shape[1]} ä¸ªç‰¹å¾")
    print(f"  æ•°æ®èŒƒå›´: [{data.min():.2f}, {data.max():.2f}]")
    
    # 3. ç”Ÿæˆæ ‡ç­¾
    labels = generate_cardiovascular_risk_labels(data)
    print(f"âœ“ ç”Ÿæˆäº†æ ‡ç­¾ï¼Œåˆ†å¸ƒ: ä½é£é™©={np.sum(labels==0)}, é«˜é£é™©={np.sum(labels==1)}")
    
    # 4. æ•°æ®é¢„å¤„ç†ï¼ˆAdaptiveFSéœ€è¦[-1, 1]èŒƒå›´çš„æ•°æ®ï¼‰
    # æ³¨æ„ï¼šæŸäº›ç‰¹å¾ï¼ˆå¦‚äºŒå…ƒå˜é‡ï¼‰ä¸éœ€è¦æ ‡å‡†åŒ–
    processed_data = data.copy()
    
    # å¯¹è¿ç»­å˜é‡è¿›è¡ŒMinMaxæ ‡å‡†åŒ–åˆ°[-1, 1]
    continuous_features = [0, 3, 4, 5, 6, 7, 8, 9,  # äººå£ç»Ÿè®¡å­¦è¿ç»­å˜é‡
                          12, 13, 14, 15, 16, 17, 18, 19,  # ç”Ÿæ´»æ–¹å¼è¿ç»­å˜é‡
                          40, 41, 42, 43, 44, 45, 46, 47, 48, 49]  # ç”Ÿç†æŒ‡æ ‡
    
    for feat_idx in continuous_features:
        feat_data = processed_data[:, feat_idx]
        feat_min, feat_max = feat_data.min(), feat_data.max()
        if feat_max > feat_min:  # é¿å…é™¤é›¶
            processed_data[:, feat_idx] = (feat_data - feat_min) / (feat_max - feat_min) * 2 - 1
    
    # å¯¹äºŒå…ƒå˜é‡å’Œåˆ†ç±»å˜é‡è¿›è¡Œé€‚å½“å¤„ç†
    binary_categorical_features = [1, 2, 10, 11] + list(range(20, 40))  # æ€§åˆ«ã€ç§æ—ã€å¸çƒŸã€é¥®é…’ã€ç—‡çŠ¶ã€ç—…å²
    for feat_idx in binary_categorical_features:
        feat_data = processed_data[:, feat_idx]
        feat_max = feat_data.max()
        if feat_max > 0:
            processed_data[:, feat_idx] = feat_data / feat_max * 2 - 1
    
    print(f"âœ“ æ•°æ®é¢„å¤„ç†å®Œæˆï¼ŒèŒƒå›´: [{processed_data.min():.2f}, {processed_data.max():.2f}]")
    
    # 5. ä¿å­˜æ–‡ä»¶
    os.makedirs(save_dir, exist_ok=True)
    
    # ä¿å­˜ä¸»æ•°æ®æ–‡ä»¶
    np.save(os.path.join(save_dir, 'small_data50.npy'), processed_data.astype(np.float32))
    print(f"âœ“ ä¿å­˜ small_data50.npy: {processed_data.shape}")
    
    # ä¿å­˜é—®é¢˜åç§°
    np.save(os.path.join(save_dir, 'names_small50.npy'), question_names)
    print(f"âœ“ ä¿å­˜ names_small50.npy: {question_names.shape}")
    
    # ä¿å­˜æ ‡ç­¾
    np.save(os.path.join(save_dir, 'labels.npy'), labels.astype(np.int32))
    print(f"âœ“ ä¿å­˜ labels.npy: {labels.shape}")
    
    print(f"\nâœ… AdaptiveFSæ•°æ®é›†åˆ›å»ºå®Œæˆï¼")
    print(f"ğŸ“ ä¿å­˜ä½ç½®: {save_dir}")
    print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"   - æ‚£è€…æ•°é‡: {n_patients}")
    print(f"   - ç‰¹å¾æ•°é‡: 50")
    print(f"   - æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(labels)}")
    print(f"   - æ•°æ®ç±»å‹: float32")
    print(f"   - æ•°æ®èŒƒå›´: [{processed_data.min():.3f}, {processed_data.max():.3f}]")
    
    return processed_data, labels, question_names

if __name__ == "__main__":
    # åˆ›å»ºAdaptiveFSæ•°æ®é›†
    data, labels, names = create_adaptivefs_dataset(n_patients=1500)
    
    # éªŒè¯æ•°æ®åŠ è½½
    print("\nğŸ” éªŒè¯æ•°æ®é›†...")
    try:
        # æµ‹è¯•æ˜¯å¦èƒ½ç”¨AdaptiveFSçš„utilsåŠ è½½
        import sys
        sys.path.append('.')
        from utils import load_data
        
        X, y, question_names, class_names, scaler = load_data(122)
        print(f"âœ… AdaptiveFSæˆåŠŸåŠ è½½æ•°æ®: {X.shape}, æ ‡ç­¾: {len(y)}")
        print(f"   é—®é¢˜åç§°ç¤ºä¾‹: {question_names[:5]}")
        print(f"   ç±»åˆ«åç§°: {class_names}")
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        
    print("\nğŸ‰ æ•°æ®é›†åˆ›å»ºå’ŒéªŒè¯å®Œæˆï¼") 